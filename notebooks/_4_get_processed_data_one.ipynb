{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99n367jq27",
   "metadata": {},
   "source": "# Notebook 4: Get Preprocessed Data (Single Dataset)\n\n## Overview\n\nThis notebook applies the **complete preprocessing pipeline** to a single FTIR dataset using the methods you selected in Notebooks 1-3. This produces publication-ready, fully preprocessed spectra.\n\n### What You'll Learn\n\n1. How to apply all preprocessing steps in the correct order\n2. How to use the convenient helper method for full preprocessing\n3. How to save your preprocessed data for analysis\n4. How to verify preprocessing results\n\n### Prerequisites\n\nBefore running this notebook, you should have completed Notebooks 1-3 to determine:\n- ✓ **Best denoising method** (Notebook 1)\n- ✓ **Best baseline correction method** (Notebook 2)\n- ✓ **Best normalization method** (Notebook 3)\n\n### Preprocessing Pipeline\n\nThe complete pipeline follows this order (order matters!):\n\n1. **Convert** to absorbance\n2. **Denoise** to remove random noise\n3. **Correct baseline** to remove drift\n4. **Handle atmospheric interference** (CO₂, H₂O)\n5. **Normalize** to make spectra comparable\n\n### Expected Output\n\n- **Fully preprocessed dataset** ready for analysis\n- **Excel file** with processed spectra\n- **Visual comparison** of original vs. preprocessed data\n- **Ready for machine learning** classification\n\n---\n\n## Step 1: Define Preprocessing Parameters\n\nBased on your results from Notebooks 1-3, update the parameters below with your selected methods."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e944fd",
   "metadata": {},
   "outputs": [],
   "source": "# Import required modules\nimport polars as pl\nfrom xpectrass import FTIRdataprocessing\nfrom xpectrass import load_villegas_camacho_2024_c4\n\n# Load your dataset\n# You can use any of the bundled datasets or your own data\ndataset = load_villegas_camacho_2024_c4()\nprint('Dataset shape:', dataset.shape)\n\n# ============================================================================\n# CONFIGURATION: Update these parameters based on your Notebooks 1-3 results\n# ============================================================================\n\n# Label column (contains polymer type information)\nLABEL_COLUMN = \"type\"\n\n# Flat windows for baseline correction evaluation\nFLAT_WINDOWS = [(1880, 1900), (2400, 2700)]\n\n# SELECTED METHOD FROM NOTEBOOK 1\nDENOISING_METHOD = 'wavelet'  # Options: 'savgol', 'wavelet', 'gaussian', 'median', etc.\n\n# SELECTED METHOD FROM NOTEBOOK 2\nBASELINE_CORRECTION_METHOD = 'aspls'  # Options: 'asls', 'airpls', 'mor', 'snip', etc.\n\n# Atmospheric correction settings\n# Define regions to exclude (completely remove from analysis)\nEXCLUDE_REGIONS = [\n    (0, 680),       # Low wavenumber noise + CO₂ bending (670 cm⁻¹)\n    (3500, 5000)    # High wavenumber noise + O–H stretch\n]\n\n# Define regions to interpolate (replace with baseline)\nINTERPOLATE_REGIONS = [\n    (1250, 2700)    # H₂O bend + CO₂ stretch regions\n]\n\n# Interpolation method for atmospheric regions\nINTERPOLATE_METHOD = \"zero\"  # Options: 'zero', 'linear', 'spline'\n\n# SELECTED METHOD FROM NOTEBOOK 3\nNORMALIZATION_METHOD = \"spectral_moments\"  # Options: 'snv', 'vector', 'minmax', 'area', etc.\n\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"PREPROCESSING CONFIGURATION\")\nprint(\"=\"*80)\nprint(f\"Dataset: Villegas-Camacho 2024 C4 ({len(dataset)} samples)\")\nprint(f\"\\nSelected Methods:\")\nprint(f\"  1. Denoising:          {DENOISING_METHOD}\")\nprint(f\"  2. Baseline:           {BASELINE_CORRECTION_METHOD}\")\nprint(f\"  3. Atmospheric:        Interpolate method = {INTERPOLATE_METHOD}\")\nprint(f\"  4. Normalization:      {NORMALIZATION_METHOD}\")\nprint(f\"\\nRegion Settings:\")\nprint(f\"  Exclude:     {EXCLUDE_REGIONS}\")\nprint(f\"  Interpolate: {INTERPOLATE_REGIONS}\")\nprint(f\"  Flat windows: {FLAT_WINDOWS}\")\nprint(\"=\"*80 + \"\\n\")\n\nprint(\"First few rows of raw data:\")\nprint(dataset.head(5))"
  },
  {
   "cell_type": "markdown",
   "id": "tdybjxy9qbn",
   "source": "### Important Notes\n\n1. **Update the methods above** with your results from Notebooks 1-3\n2. **Verify your settings** match your experimental requirements\n3. **Region settings** should match your data characteristics\n\n---\n\n## Step 2: Apply Complete Preprocessing Pipeline\n\nNow we'll apply all preprocessing steps in one convenient method call.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a91dcf",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize the preprocessing pipeline\nprint(\"Initializing FTIRdataprocessing pipeline...\")\nfdp = FTIRdataprocessing(\n    df=dataset,\n    label_column=LABEL_COLUMN,\n    exclude_regions=EXCLUDE_REGIONS,\n    interpolate_regions=INTERPOLATE_REGIONS,\n    flat_windows=FLAT_WINDOWS\n)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"APPLYING FULL PREPROCESSING PIPELINE\")\nprint(\"=\"*80)\nprint(\"\\nProcessing steps:\")\nprint(\"  Step 1/5: Converting to absorbance...\")\nprint(\"  Step 2/5: Denoising spectra...\")\nprint(\"  Step 3/5: Correcting baseline...\")\nprint(\"  Step 4/5: Handling atmospheric interference...\")\nprint(\"  Step 5/5: Normalizing spectra...\")\nprint(\"\\nThis may take a few minutes for large datasets...\\n\")\n\n# Apply full preprocessing pipeline:\n# 1. Convert to absorbance\n# 2. Denoise\n# 3. Correct baseline\n# 4. Atmospheric correction (exclude + interpolate)\n# 5. Normalize\n# \n# _get_normalized_data() is a convenience method that applies all steps\ndf_preprocessed = fdp._get_normalized_data(\n    denoising_method=DENOISING_METHOD,\n    baseline_correction_method=BASELINE_CORRECTION_METHOD,\n    interpolate_method=INTERPOLATE_METHOD,\n    normalization_method=NORMALIZATION_METHOD,\n    plot=True,  # Show before/after comparison\n)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"PREPROCESSING COMPLETE!\")\nprint(\"=\"*80)\nprint(f\"\\nOriginal data shape:     {dataset.shape}\")\nprint(f\"Preprocessed data shape: {df_preprocessed.shape}\")\nprint(f\"\\nFeatures:\")\nprint(f\"  Original wavenumbers:    {dataset.shape[1] - 1}\")\nprint(f\"  After region exclusion:  {df_preprocessed.shape[1] - 1}\")\nprint(f\"  Reduction:               {dataset.shape[1] - df_preprocessed.shape[1]} features removed\")\n\n# Save the fully preprocessed data\noutput_file = 'DenoisedBaselineAtmosphericCorrectedNormalizedData.xlsx'\nprint(f\"\\nSaving preprocessed data to: {output_file}\")\ndf_preprocessed.to_excel(output_file, index=False)\nprint(f\"✓ Data saved successfully!\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"PREPROCESSING SUMMARY\")\nprint(\"=\"*80)\nprint(f\"✓ {len(df_preprocessed)} spectra processed\")\nprint(f\"✓ {df_preprocessed[LABEL_COLUMN].nunique()} polymer types\")\nprint(f\"✓ {df_preprocessed.shape[1] - 1} wavenumber features\")\nprint(f\"✓ Data is ready for analysis and machine learning\")\nprint(\"=\"*80)"
  },
  {
   "cell_type": "markdown",
   "id": "z0ylzfk1ihh",
   "source": "### What Just Happened?\n\nThe `_get_normalized_data()` method applied all preprocessing steps sequentially:\n\n1. **Conversion**: Transmittance → Absorbance (if needed)\n2. **Denoising**: Applied your selected denoising method\n3. **Baseline Correction**: Applied your selected baseline method\n4. **Atmospheric Correction**: \n   - Excluded regions outside 680-3500 cm⁻¹\n   - Interpolated over H₂O and CO₂ regions (1250-2700 cm⁻¹)\n5. **Normalization**: Applied your selected normalization method\n\n### Output Files\n\n- **`DenoisedBaselineAtmosphericCorrectedNormalizedData.xlsx`**: \n  - Fully preprocessed spectra\n  - Ready for analysis and machine learning\n  - Can be loaded directly into FTIRdataanalysis class\n\n### Alternative: Step-by-Step Approach\n\nIf you prefer more control, you can apply each step manually:\n\n```python\n# Manual approach (equivalent to _get_normalized_data())\nfdp = FTIRdataprocessing(df, label_column=\"type\", \n                         exclude_regions=EXCLUDE_REGIONS,\n                         interpolate_regions=INTERPOLATE_REGIONS,\n                         flat_windows=FLAT_WINDOWS)\n\n# Step 1: Convert\nfdp.convert(mode=\"to_absorbance\", plot=True)\n\n# Step 2: Denoise\nfdp.denoise_spect(method=DENOISING_METHOD, plot=True)\n\n# Step 3: Baseline correction\nfdp.correct_baseline(method=BASELINE_CORRECTION_METHOD, plot=True)\n\n# Step 4: Atmospheric correction\nfdp.exclude_interpolate(method=INTERPOLATE_METHOD, plot=True)\n\n# Step 5: Normalize\nfdp.normalize(method=NORMALIZATION_METHOD, plot=True)\n\n# Get final data\ndf_preprocessed = fdp.df_norm\n```\n\nBoth approaches produce identical results. The helper method is more convenient, while the manual approach provides more visualization options.\n\n---\n\n## Next Steps\n\nYour preprocessed data is now ready for:\n\n1. **Machine Learning Classification** (see Notebook 6)\n   - Train classification models\n   - Evaluate performance\n   - Hyperparameter tuning\n   - SHAP explainability\n\n2. **Statistical Analysis** (see Notebook 6)\n   - PCA, t-SNE, UMAP visualization\n   - ANOVA analysis\n   - Clustering analysis\n   - Correlation studies\n\n3. **External Analysis**\n   - Export to other software (The Unscrambler, SIMCA, etc.)\n   - Custom analysis pipelines\n   - Publication-ready figures\n\n### Loading Preprocessed Data Later\n\nTo load your preprocessed data in a future session:\n\n```python\nimport pandas as pd\nfrom xpectrass import FTIRdataanalysis\n\n# Load preprocessed data\ndf = pd.read_excel('DenoisedBaselineAtmosphericCorrectedNormalizedData.xlsx', index_col=0)\n\n# Initialize analysis\nanalysis = FTIRdataanalysis(df, label_column=\"type\")\n\n# Proceed with analysis...\nanalysis.plot_pca()\nanalysis.run_all_models()\n```\n\n---\n\n## Conclusion\n\nYou've successfully applied the complete preprocessing pipeline to your FTIR dataset! The data is now optimally prepared for analysis. \n\n- For processing **all bundled datasets** at once, see Notebook 5\n- For **analysis and machine learning**, proceed to Notebook 6",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ToF-SIMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}