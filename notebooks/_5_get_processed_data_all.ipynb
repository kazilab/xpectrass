{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99n367jq27",
   "metadata": {},
   "source": [
    "# Notebook 5: Get Preprocessed Data (All Datasets)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook applies the **complete preprocessing pipeline to ALL bundled FTIR datasets** at once, producing publication-ready preprocessed spectra for the entire Xpectrass dataset collection. It also computes spectral derivatives and combines datasets into unified files.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. How to batch-process multiple FTIR datasets efficiently\n",
    "2. How to apply consistent preprocessing across different studies\n",
    "3. How to compute spectral derivatives (1st and 2nd order)\n",
    "4. How to combine multiple datasets into a unified format\n",
    "5. How to save processed data for downstream analysis\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Before running this notebook, you should have completed Notebooks 1-3 to determine:\n",
    "- ✓ **Best denoising method** (Notebook 1)\n",
    "- ✓ **Best baseline correction method** (Notebook 2)\n",
    "- ✓ **Best normalization method** (Notebook 3)\n",
    "\n",
    "### Bundled Datasets\n",
    "\n",
    "Xpectrass includes 6 published FTIR datasets:\n",
    "- **jung_2018**: Jung et al. (2018) microplastics study\n",
    "- **kedzierski_2019**: Kedzierski et al. (2019) environmental samples\n",
    "- **kedzierski_2019_u**: Kedzierski et al. (2019) unknown samples\n",
    "- **frond_2021**: Frond et al. (2021) polymer characterization\n",
    "- **villegas_camacho_2024_c4**: Villegas-Camacho et al. (2024) 4 cm⁻¹ resolution\n",
    "- **villegas_camacho_2024_c8**: Villegas-Camacho et al. (2024) 8 cm⁻¹ resolution\n",
    "\n",
    "### Preprocessing Pipeline\n",
    "\n",
    "Each dataset undergoes the same pipeline (order matters!):\n",
    "\n",
    "1. **Convert** to absorbance\n",
    "2. **Denoise** to remove random noise\n",
    "3. **Correct baseline** to remove drift\n",
    "4. **Handle atmospheric interference** (CO₂, H₂O)\n",
    "5. **Normalize** to make spectra comparable\n",
    "6. **Compute derivatives** (optional, for enhanced spectral features)\n",
    "\n",
    "### Spectral Derivatives\n",
    "\n",
    "**Why compute derivatives?**\n",
    "- **1st derivative**: Enhances spectral resolution, highlights subtle peaks\n",
    "- **2nd derivative**: Further sharpens peaks, useful for overlapping bands\n",
    "- Derivatives are often used in chemometric analysis and machine learning\n",
    "- Can improve classification performance in some cases\n",
    "\n",
    "**Parameters:**\n",
    "- `order`: 1 for first derivative, 2 for second derivative\n",
    "- `window_length`: Savitzky-Golay filter window size (15 is typical)\n",
    "- `polyorder`: Polynomial order for S-G filter (3 is typical)\n",
    "- `delta`: Spacing between data points (1.0 for unit spacing)\n",
    "\n",
    "### Expected Output\n",
    "\n",
    "By the end of this notebook, you'll have:\n",
    "- **6 preprocessed datasets** (one for each study)\n",
    "- **6 first derivative datasets**\n",
    "- **6 second derivative datasets**\n",
    "- **3 combined files** (normalized, 1st derivative, 2nd derivative)\n",
    "- **2 combined normalized derivative files**\n",
    "- All files saved in compressed CSV format for analysis\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Load All Datasets and Define Parameters\n",
    "\n",
    "First, we'll load all bundled datasets and configure preprocessing parameters based on your Notebooks 1-3 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e944fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BATCH PREPROCESSING CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "Selected Methods:\n",
      "  1. Denoising:          wavelet\n",
      "  2. Baseline:           aspls\n",
      "  3. Atmospheric:        Interpolate method = zero\n",
      "  4. Normalization:      snv_detrend\n",
      "\n",
      "Region Settings:\n",
      "  Exclude:     [(0, 679), (3001, 5000)]\n",
      "  Interpolate: [(1250, 2700)]\n",
      "  Flat windows: [(1880, 1900), (2400, 2700)]\n",
      "================================================================================\n",
      "\n",
      "Dataset Information:\n",
      "{'jung_2018': {'exists': True, 'path': '/Users/julhashkazi/Documents/PythonScripts/FTIR/scripts/notebooks/.conda/lib/python3.11/site-packages/xpectrass/data/jung_2018.csv.xz', 'filename': 'jung_2018.csv.xz', 'size_mb': 1.5899505615234375}, 'kedzierski_2019': {'exists': True, 'path': '/Users/julhashkazi/Documents/PythonScripts/FTIR/scripts/notebooks/.conda/lib/python3.11/site-packages/xpectrass/data/kedzierski_2019.csv.xz', 'filename': 'kedzierski_2019.csv.xz', 'size_mb': 7.486408233642578}, 'kedzierski_2019_u': {'exists': True, 'path': '/Users/julhashkazi/Documents/PythonScripts/FTIR/scripts/notebooks/.conda/lib/python3.11/site-packages/xpectrass/data/kedzierski_2019_u.csv.xz', 'filename': 'kedzierski_2019_u.csv.xz', 'size_mb': 10.197105407714844}, 'frond_2021': {'exists': True, 'path': '/Users/julhashkazi/Documents/PythonScripts/FTIR/scripts/notebooks/.conda/lib/python3.11/site-packages/xpectrass/data/frond_2021.csv.xz', 'filename': 'frond_2021.csv.xz', 'size_mb': 1.553314208984375}, 'villegas_camacho_2024_c4': {'exists': True, 'path': '/Users/julhashkazi/Documents/PythonScripts/FTIR/scripts/notebooks/.conda/lib/python3.11/site-packages/xpectrass/data/villegas_camacho_2024_c4.csv.xz', 'filename': 'villegas_camacho_2024_c4.csv.xz', 'size_mb': 18.144927978515625}, 'villegas_camacho_2024_c8': {'exists': True, 'path': '/Users/julhashkazi/Documents/PythonScripts/FTIR/scripts/notebooks/.conda/lib/python3.11/site-packages/xpectrass/data/villegas_camacho_2024_c8.csv.xz', 'filename': 'villegas_camacho_2024_c8.csv.xz', 'size_mb': 12.561935424804688}}\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import polars as pl\n",
    "from xpectrass import FTIRdataprocessing\n",
    "from xpectrass import load_all_datasets, get_data_info\n",
    "\n",
    "# Load all bundled datasets at once\n",
    "# This returns a dictionary with dataset names as keys\n",
    "dataset = load_all_datasets()\n",
    "info = get_data_info()\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION: Update these parameters based on your Notebooks 1-3 results\n",
    "# ============================================================================\n",
    "\n",
    "# Label column (contains polymer type information)\n",
    "LABEL_COLUMN = \"type\"\n",
    "\n",
    "# Flat windows for baseline correction evaluation\n",
    "FLAT_WINDOWS = [(1880, 1900), (2400, 2700)]\n",
    "\n",
    "# SELECTED METHOD FROM NOTEBOOK 1\n",
    "DENOISING_METHOD = 'wavelet'  # Options: 'savgol', 'wavelet', 'gaussian', 'median', etc.\n",
    "\n",
    "# SELECTED METHOD FROM NOTEBOOK 2\n",
    "BASELINE_CORRECTION_METHOD = 'aspls'  # Options: 'asls', 'airpls', 'mor', 'snip', etc.\n",
    "\n",
    "# Atmospheric correction settings\n",
    "# Define regions to exclude (completely remove from analysis)\n",
    "EXCLUDE_REGIONS = [\n",
    "    (0, 679),       # Exclude everything below 680, CO₂ bending mode (670 cm⁻¹)\n",
    "    (3001, 5000)    # Exclude everything above 3000, O–H stretch region\n",
    "]\n",
    "\n",
    "# Define regions to interpolate (replace with baseline)\n",
    "INTERPOLATE_REGIONS = [\n",
    "    (1250, 2700)    # Interpolate over H₂O bend + CO₂ stretch regions\n",
    "]\n",
    "\n",
    "# Interpolation method for atmospheric regions\n",
    "INTERPOLATE_METHOD = \"zero\"  # Options: 'zero', 'linear', 'spline'\n",
    "\n",
    "# SELECTED METHOD FROM NOTEBOOK 3\n",
    "NORMALIZATION_METHOD = \"snv_detrend\"  # Options: 'snv', 'vector', 'minmax', 'area', etc.\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BATCH PREPROCESSING CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nSelected Methods:\")\n",
    "print(f\"  1. Denoising:          {DENOISING_METHOD}\")\n",
    "print(f\"  2. Baseline:           {BASELINE_CORRECTION_METHOD}\")\n",
    "print(f\"  3. Atmospheric:        Interpolate method = {INTERPOLATE_METHOD}\")\n",
    "print(f\"  4. Normalization:      {NORMALIZATION_METHOD}\")\n",
    "print(f\"\\nRegion Settings:\")\n",
    "print(f\"  Exclude:     {EXCLUDE_REGIONS}\")\n",
    "print(f\"  Interpolate: {INTERPOLATE_REGIONS}\")\n",
    "print(f\"  Flat windows: {FLAT_WINDOWS}\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c36c9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Extract Individual Datasets\n",
    "\n",
    "Now we'll extract each dataset from the dictionary for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8d2c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INDIVIDUAL DATASET SHAPES\n",
      "================================================================================\n",
      "jung_2018:                 (800, 3556)\n",
      "kedzierski_2019:           (970, 1767)\n",
      "kedzierski_2019_u:         (4064, 1768)\n",
      "frond_2021:                (380, 1874)\n",
      "villegas_camacho_2024_c4:  (3000, 3741)\n",
      "villegas_camacho_2024_c8:  (3000, 1874)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Extract individual datasets from the dictionary\n",
    "jung_2018 = dataset['jung_2018']\n",
    "kedzierski_2019 = dataset['kedzierski_2019']\n",
    "kedzierski_2019_u = dataset['kedzierski_2019_u']\n",
    "frond_2021 = dataset['frond_2021']\n",
    "villegas_camacho_2024_c4 = dataset['villegas_camacho_2024_c4']\n",
    "villegas_camacho_2024_c8 = dataset['villegas_camacho_2024_c8']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"INDIVIDUAL DATASET SHAPES\")\n",
    "print(\"=\"*80)\n",
    "print(f'jung_2018:                 {jung_2018.shape}')\n",
    "print(f'kedzierski_2019:           {kedzierski_2019.shape}')\n",
    "print(f'kedzierski_2019_u:         {kedzierski_2019_u.shape}')\n",
    "print(f'frond_2021:                {frond_2021.shape}')\n",
    "print(f'villegas_camacho_2024_c4:  {villegas_camacho_2024_c4.shape}')\n",
    "print(f'villegas_camacho_2024_c8:  {villegas_camacho_2024_c8.shape}')\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436bef6d",
   "metadata": {},
   "source": [
    "### Create a processed_data folder to store processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eyqn8j7tw4u",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created 'processed_data' folder\n"
     ]
    }
   ],
   "source": [
    "# Create processed_data folder if it doesn't exist\n",
    "import os\n",
    "\n",
    "processed_data_dir = 'processed_data'\n",
    "if not os.path.exists(processed_data_dir):\n",
    "    os.makedirs(processed_data_dir)\n",
    "    print(f\"✓ Created '{processed_data_dir}' folder\")\n",
    "else:\n",
    "    print(f\"✓ '{processed_data_dir}' folder already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tb72t9e3bsr",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Process Each Dataset\n",
    "\n",
    "Now we'll apply the complete preprocessing pipeline to each dataset individually. For each dataset, we will:\n",
    "1. Apply full preprocessing (denoising → baseline → atmospheric → normalization)\n",
    "2. Compute 1st derivative spectra\n",
    "3. Compute 2nd derivative spectra\n",
    "\n",
    "This may take several minutes depending on dataset sizes.\n",
    "\n",
    "### Dataset 1: jung_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59a91dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/6] Processing jung_2018...\n",
      "  → Applying full preprocessing (denoise + baseline + atmospheric + normalize)...\n",
      "Auto-detected: Transmittance → Converting to Absorbance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Denoising (wavelet): 100%|██████████| 800/800 [00:00<00:00, 11779.23it/s]\n",
      "WARNING - Denoising produced 54816 negative absorbance values (1.9% of valid points, min=-0.0896). This is physically invalid and may indicate: (1) aggressive smoothing parameters, (2) baseline drift in input data, or (3) input data already near zero. Recommendations: Apply baseline correction before denoising, or adjust denoising parameters (e.g., reduce window_length for savgol).\n",
      "Baseline correction (aspls): 100%|██████████| 800/800 [00:18<00:00, 42.49it/s]\n",
      "WARNING - Baseline correction produced 958757 negative absorbance values (33.7% of valid points, min=-0.0032). This is physically invalid. The baseline may be over-estimated. Recommendations: (1) Set clip_negative=True to clip values to 0, (2) Try different baseline method (e.g., 'asls', 'arpls'), or (3) Adjust method parameters (e.g., increase lam, decrease p).\n",
      "Processing Regions: 100%|██████████| 800/800 [00:00<00:00, 10708.19it/s]\n",
      "Normalization (snv_detrend): 100%|██████████| 800/800 [00:00<00:00, 11272.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Computing 1st derivative spectra...\n",
      "Computing 1st derivative for 800 samples...\n",
      "  → Computing 2nd derivative spectra...\n",
      "Computing 2nd derivative for 800 samples...\n",
      "✓ jung_2018 complete: (800, 2326)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[1/6] Processing jung_2018...\")\n",
    "\n",
    "# Initialize FTIRdataprocessing class for jung_2018\n",
    "fdp1 = FTIRdataprocessing(\n",
    "    df=jung_2018,\n",
    "    label_column=LABEL_COLUMN,\n",
    "    exclude_regions=EXCLUDE_REGIONS,\n",
    "    interpolate_regions=INTERPOLATE_REGIONS,\n",
    "    flat_windows=FLAT_WINDOWS\n",
    ")\n",
    "\n",
    "# Apply full preprocessing pipeline\n",
    "print(\"  → Applying full preprocessing (denoise + baseline + atmospheric + normalize)...\")\n",
    "jung_2018_corr = fdp1._get_normalized_data(\n",
    "    denoising_method=DENOISING_METHOD,\n",
    "    baseline_correction_method=BASELINE_CORRECTION_METHOD,\n",
    "    interpolate_method=INTERPOLATE_METHOD,\n",
    "    normalization_method=NORMALIZATION_METHOD,\n",
    "    plot=False,\n",
    ")\n",
    "\n",
    "# Compute 1st derivative\n",
    "print(\"  → Computing 1st derivative spectra...\")\n",
    "jung_2018_deriv1 = fdp1.derivatives(\n",
    "    data=jung_2018_corr,\n",
    "    order=1,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "# Compute 2nd derivative\n",
    "print(\"  → Computing 2nd derivative spectra...\")\n",
    "jung_2018_deriv2 = fdp1.derivatives(\n",
    "    data=jung_2018_corr,\n",
    "    order=2,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "print(f\"✓ jung_2018 complete: {jung_2018_corr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7woeg8u5plr",
   "metadata": {},
   "source": [
    "### Dataset 2: kedzierski_2019\n",
    "\n",
    "**Note**: This dataset is already in absorbance mode and pre-processed, so we only compute derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "274f7091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/6] Processing kedzierski_2019...\n",
      "  → Dataset already preprocessed, using as-is...\n",
      "  → Computing 1st derivative spectra...\n",
      "Computing 1st derivative for 970 samples...\n",
      "  → Computing 2nd derivative spectra...\n",
      "Computing 2nd derivative for 970 samples...\n",
      "✓ kedzierski_2019 complete: (970, 1767)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[2/6] Processing kedzierski_2019...\")\n",
    "\n",
    "# Initialize FTIRdataprocessing class for kedzierski_2019\n",
    "fdp2 = FTIRdataprocessing(\n",
    "    df=kedzierski_2019,\n",
    "    label_column=LABEL_COLUMN,\n",
    "    exclude_regions=EXCLUDE_REGIONS,\n",
    "    interpolate_regions=INTERPOLATE_REGIONS,\n",
    "    flat_windows=FLAT_WINDOWS\n",
    ")\n",
    "\n",
    "# This dataset is already preprocessed, so we just copy it\n",
    "print(\"  → Dataset already preprocessed, using as-is...\")\n",
    "kedzierski_2019_corr = kedzierski_2019.copy()\n",
    "\n",
    "# Compute 1st derivative\n",
    "print(\"  → Computing 1st derivative spectra...\")\n",
    "kedzierski_2019_deriv1 = fdp2.derivatives(\n",
    "    data=kedzierski_2019_corr,\n",
    "    order=1,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "# Compute 2nd derivative\n",
    "print(\"  → Computing 2nd derivative spectra...\")\n",
    "kedzierski_2019_deriv2 = fdp2.derivatives(\n",
    "    data=kedzierski_2019_corr,\n",
    "    order=2,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "print(f\"✓ kedzierski_2019 complete: {kedzierski_2019_corr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rkb8doyyiqn",
   "metadata": {},
   "source": [
    "### Dataset 3: kedzierski_2019_u (Unknown samples)\n",
    "\n",
    "**Note**: This dataset is also already preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62ead1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/6] Processing kedzierski_2019_u...\n",
      "  → Dataset already preprocessed, using as-is...\n",
      "  → Computing 1st derivative spectra...\n",
      "Computing 1st derivative for 4064 samples...\n",
      "  → Computing 2nd derivative spectra...\n",
      "Computing 2nd derivative for 4064 samples...\n",
      "✓ kedzierski_2019_u complete: (4064, 1768)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[3/6] Processing kedzierski_2019_u...\")\n",
    "\n",
    "# Initialize FTIRdataprocessing class for kedzierski_2019_u\n",
    "fdp3 = FTIRdataprocessing(\n",
    "    df=kedzierski_2019_u,\n",
    "    label_column=LABEL_COLUMN,\n",
    "    exclude_regions=EXCLUDE_REGIONS,\n",
    "    interpolate_regions=INTERPOLATE_REGIONS,\n",
    "    flat_windows=FLAT_WINDOWS\n",
    ")\n",
    "\n",
    "# This dataset is already preprocessed, so we just copy it\n",
    "print(\"  → Dataset already preprocessed, using as-is...\")\n",
    "kedzierski_2019_u_corr = kedzierski_2019_u.copy()\n",
    "\n",
    "# Compute 1st derivative\n",
    "print(\"  → Computing 1st derivative spectra...\")\n",
    "kedzierski_2019_u_deriv1 = fdp3.derivatives(\n",
    "    data=kedzierski_2019_u_corr,\n",
    "    order=1,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "# Compute 2nd derivative\n",
    "print(\"  → Computing 2nd derivative spectra...\")\n",
    "kedzierski_2019_u_deriv2 = fdp3.derivatives(\n",
    "    data=kedzierski_2019_u_corr,\n",
    "    order=2,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "print(f\"✓ kedzierski_2019_u complete: {kedzierski_2019_u_corr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55kawwbgsg5",
   "metadata": {},
   "source": [
    "### Dataset 4: frond_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "487b53c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 0 negative and 54720 zero transmittance values. These are physically invalid and will be clipped to 0.01% for conversion. This indicates data quality issues in the input.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/6] Processing frond_2021...\n",
      "  → Applying full preprocessing (denoise + baseline + atmospheric + normalize)...\n",
      "Auto-detected: Transmittance → Converting to Absorbance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Denoising (wavelet): 100%|██████████| 380/380 [00:00<00:00, 17757.03it/s]\n",
      "WARNING - Denoising produced 158125 negative absorbance values (22.3% of valid points, min=-0.0549). This is physically invalid and may indicate: (1) aggressive smoothing parameters, (2) baseline drift in input data, or (3) input data already near zero. Recommendations: Apply baseline correction before denoising, or adjust denoising parameters (e.g., reduce window_length for savgol).\n",
      "Baseline correction (aspls): 100%|██████████| 380/380 [00:02<00:00, 153.22it/s]\n",
      "WARNING - Baseline correction produced 240213 negative absorbance values (33.8% of valid points, min=-0.4866). This is physically invalid. The baseline may be over-estimated. Recommendations: (1) Set clip_negative=True to clip values to 0, (2) Try different baseline method (e.g., 'asls', 'arpls'), or (3) Adjust method parameters (e.g., increase lam, decrease p).\n",
      "Processing Regions: 100%|██████████| 380/380 [00:00<00:00, 16745.84it/s]\n",
      "Normalization (snv_detrend): 100%|██████████| 380/380 [00:00<00:00, 15526.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Computing 1st derivative spectra...\n",
      "Computing 1st derivative for 380 samples...\n",
      "  → Computing 2nd derivative spectra...\n",
      "Computing 2nd derivative for 380 samples...\n",
      "✓ frond_2021 complete: (380, 1209)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[4/6] Processing frond_2021...\")\n",
    "\n",
    "# Initialize FTIRdataprocessing class for frond_2021\n",
    "fdp4 = FTIRdataprocessing(\n",
    "    df=frond_2021,\n",
    "    label_column=LABEL_COLUMN,\n",
    "    exclude_regions=EXCLUDE_REGIONS,\n",
    "    interpolate_regions=INTERPOLATE_REGIONS,\n",
    "    flat_windows=FLAT_WINDOWS\n",
    ")\n",
    "\n",
    "# Apply full preprocessing pipeline\n",
    "print(\"  → Applying full preprocessing (denoise + baseline + atmospheric + normalize)...\")\n",
    "frond_2021_corr = fdp4._get_normalized_data(\n",
    "    denoising_method=DENOISING_METHOD,\n",
    "    baseline_correction_method=BASELINE_CORRECTION_METHOD,\n",
    "    interpolate_method=INTERPOLATE_METHOD,\n",
    "    normalization_method=NORMALIZATION_METHOD,\n",
    "    plot=False,\n",
    ")\n",
    "\n",
    "# Compute 1st derivative\n",
    "print(\"  → Computing 1st derivative spectra...\")\n",
    "frond_2021_deriv1 = fdp4.derivatives(\n",
    "    data=frond_2021_corr,\n",
    "    order=1,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "# Compute 2nd derivative\n",
    "print(\"  → Computing 2nd derivative spectra...\")\n",
    "frond_2021_deriv2 = fdp4.derivatives(\n",
    "    data=frond_2021_corr,\n",
    "    order=2,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "print(f\"✓ frond_2021 complete: {frond_2021_corr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2wjeb9jrdgk",
   "metadata": {},
   "source": [
    "### Dataset 5: villegas_camacho_2024_c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d020773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/6] Processing villegas_camacho_2024_c4...\n",
      "  → Applying full preprocessing (denoise + baseline + atmospheric + normalize)...\n",
      "Auto-detected: Transmittance → Converting to Absorbance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Denoising (wavelet): 100%|██████████| 3000/3000 [00:00<00:00, 11205.07it/s]\n",
      "WARNING - Denoising produced 5071997 negative absorbance values (45.3% of valid points, min=-0.0852). This is physically invalid and may indicate: (1) aggressive smoothing parameters, (2) baseline drift in input data, or (3) input data already near zero. Recommendations: Apply baseline correction before denoising, or adjust denoising parameters (e.g., reduce window_length for savgol).\n",
      "Baseline correction (aspls): 100%|██████████| 3000/3000 [01:19<00:00, 37.80it/s]\n",
      "WARNING - Baseline correction produced 3334901 negative absorbance values (29.8% of valid points, min=-0.0115). This is physically invalid. The baseline may be over-estimated. Recommendations: (1) Set clip_negative=True to clip values to 0, (2) Try different baseline method (e.g., 'asls', 'arpls'), or (3) Adjust method parameters (e.g., increase lam, decrease p).\n",
      "Processing Regions: 100%|██████████| 3000/3000 [00:00<00:00, 9109.60it/s]\n",
      "Normalization (snv_detrend): 100%|██████████| 3000/3000 [00:00<00:00, 10857.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Computing 1st derivative spectra...\n",
      "Computing 1st derivative for 3000 samples...\n",
      "  → Computing 2nd derivative spectra...\n",
      "Computing 2nd derivative for 3000 samples...\n",
      "✓ villegas_camacho_2024_c4 complete: (3000, 2413)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5/6] Processing villegas_camacho_2024_c4...\")\n",
    "\n",
    "# Initialize FTIRdataprocessing class for villegas_camacho_2024_c4\n",
    "fdp5 = FTIRdataprocessing(\n",
    "    df=villegas_camacho_2024_c4,\n",
    "    label_column=LABEL_COLUMN,\n",
    "    exclude_regions=EXCLUDE_REGIONS,\n",
    "    interpolate_regions=INTERPOLATE_REGIONS,\n",
    "    flat_windows=FLAT_WINDOWS\n",
    ")\n",
    "\n",
    "# Apply full preprocessing pipeline\n",
    "print(\"  → Applying full preprocessing (denoise + baseline + atmospheric + normalize)...\")\n",
    "villegas_camacho_2024_c4_corr = fdp5._get_normalized_data(\n",
    "    denoising_method=DENOISING_METHOD,\n",
    "    baseline_correction_method=BASELINE_CORRECTION_METHOD,\n",
    "    interpolate_method=INTERPOLATE_METHOD,\n",
    "    normalization_method=NORMALIZATION_METHOD,\n",
    "    plot=False,\n",
    ")\n",
    "\n",
    "# Compute 1st derivative\n",
    "print(\"  → Computing 1st derivative spectra...\")\n",
    "villegas_camacho_2024_c4_deriv1 = fdp5.derivatives(\n",
    "    data=villegas_camacho_2024_c4_corr,\n",
    "    order=1,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "# Compute 2nd derivative\n",
    "print(\"  → Computing 2nd derivative spectra...\")\n",
    "villegas_camacho_2024_c4_deriv2 = fdp5.derivatives(\n",
    "    data=villegas_camacho_2024_c4_corr,\n",
    "    order=2,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "print(f\"✓ villegas_camacho_2024_c4 complete: {villegas_camacho_2024_c4_corr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cia85r16f0k",
   "metadata": {},
   "source": [
    "### Dataset 6: villegas_camacho_2024_c8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5885b710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/6] Processing villegas_camacho_2024_c8...\n",
      "  → Applying full preprocessing (denoise + baseline + atmospheric + normalize)...\n",
      "Auto-detected: Transmittance → Converting to Absorbance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Denoising (wavelet): 100%|██████████| 3000/3000 [00:00<00:00, 17523.90it/s]\n",
      "WARNING - Denoising produced 2574958 negative absorbance values (45.9% of valid points, min=-0.1571). This is physically invalid and may indicate: (1) aggressive smoothing parameters, (2) baseline drift in input data, or (3) input data already near zero. Recommendations: Apply baseline correction before denoising, or adjust denoising parameters (e.g., reduce window_length for savgol).\n",
      "Baseline correction (aspls): 100%|██████████| 3000/3000 [00:44<00:00, 67.70it/s]\n",
      "WARNING - Baseline correction produced 1589720 negative absorbance values (28.4% of valid points, min=-0.0384). This is physically invalid. The baseline may be over-estimated. Recommendations: (1) Set clip_negative=True to clip values to 0, (2) Try different baseline method (e.g., 'asls', 'arpls'), or (3) Adjust method parameters (e.g., increase lam, decrease p).\n",
      "Processing Regions: 100%|██████████| 3000/3000 [00:00<00:00, 16536.77it/s]\n",
      "Normalization (snv_detrend): 100%|██████████| 3000/3000 [00:00<00:00, 15719.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Computing 1st derivative spectra...\n",
      "Computing 1st derivative for 3000 samples...\n",
      "  → Computing 2nd derivative spectra...\n",
      "Computing 2nd derivative for 3000 samples...\n",
      "✓ villegas_camacho_2024_c8 complete: (3000, 1209)\n",
      "\n",
      "================================================================================\n",
      "ALL DATASETS PROCESSED SUCCESSFULLY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[6/6] Processing villegas_camacho_2024_c8...\")\n",
    "\n",
    "# Initialize FTIRdataprocessing class for villegas_camacho_2024_c8\n",
    "fdp6 = FTIRdataprocessing(\n",
    "    df=villegas_camacho_2024_c8,\n",
    "    label_column=LABEL_COLUMN,\n",
    "    exclude_regions=EXCLUDE_REGIONS,\n",
    "    interpolate_regions=INTERPOLATE_REGIONS,\n",
    "    flat_windows=FLAT_WINDOWS\n",
    ")\n",
    "\n",
    "# Apply full preprocessing pipeline\n",
    "print(\"  → Applying full preprocessing (denoise + baseline + atmospheric + normalize)...\")\n",
    "villegas_camacho_2024_c8_corr = fdp6._get_normalized_data(\n",
    "    denoising_method=DENOISING_METHOD,\n",
    "    baseline_correction_method=BASELINE_CORRECTION_METHOD,\n",
    "    interpolate_method=INTERPOLATE_METHOD,\n",
    "    normalization_method=NORMALIZATION_METHOD,\n",
    "    plot=False,\n",
    ")\n",
    "\n",
    "# Compute 1st derivative\n",
    "print(\"  → Computing 1st derivative spectra...\")\n",
    "villegas_camacho_2024_c8_deriv1 = fdp6.derivatives(\n",
    "    data=villegas_camacho_2024_c8_corr,\n",
    "    order=1,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "# Compute 2nd derivative\n",
    "print(\"  → Computing 2nd derivative spectra...\")\n",
    "villegas_camacho_2024_c8_deriv2 = fdp6.derivatives(\n",
    "    data=villegas_camacho_2024_c8_corr,\n",
    "    order=2,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "print(f\"✓ villegas_camacho_2024_c8 complete: {villegas_camacho_2024_c8_corr.shape}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL DATASETS PROCESSED SUCCESSFULLY\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rynocy5djxf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Clean Up Metadata Columns\n",
    "\n",
    "Remove the 'study' column from preprocessed datasets before combining (it will be re-added during combination with proper study names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7d54270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CLEANING UP METADATA COLUMNS\n",
      "================================================================================\n",
      "Removing 'study' column from all datasets (will be re-added during combination)...\n",
      "\n",
      "✓ Cleanup complete\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLEANING UP METADATA COLUMNS\")\n",
    "print(\"=\"*80)\n",
    "print(\"Removing 'study' column from all datasets (will be re-added during combination)...\\n\")\n",
    "\n",
    "# Remove 'study' column from all corrected datasets\n",
    "jung_2018_corr.drop(columns=['study'], inplace=True)\n",
    "kedzierski_2019_corr.drop(columns=['study'], inplace=True)\n",
    "kedzierski_2019_u_corr.drop(columns=['study'], inplace=True)\n",
    "frond_2021_corr.drop(columns=['study'], inplace=True)\n",
    "villegas_camacho_2024_c4_corr.drop(columns=['study'], inplace=True)\n",
    "villegas_camacho_2024_c8_corr.drop(columns=['study'], inplace=True)\n",
    "\n",
    "print(\"✓ Cleanup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49a10174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PREPROCESSED DATA SHAPES (normalized)\n",
      "================================================================================\n",
      "jung_2018:                 (800, 2325)\n",
      "kedzierski_2019:           (970, 1766)\n",
      "kedzierski_2019_u:         (4064, 1767)\n",
      "frond_2021:                (380, 1208)\n",
      "villegas_camacho_2024_c4:  (3000, 2412)\n",
      "villegas_camacho_2024_c8:  (3000, 1208)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREPROCESSED DATA SHAPES (normalized)\")\n",
    "print(\"=\"*80)\n",
    "print(f'jung_2018:                 {jung_2018_corr.shape}')\n",
    "print(f'kedzierski_2019:           {kedzierski_2019_corr.shape}')\n",
    "print(f'kedzierski_2019_u:         {kedzierski_2019_u_corr.shape}')\n",
    "print(f'frond_2021:                {frond_2021_corr.shape}')\n",
    "print(f'villegas_camacho_2024_c4:  {villegas_camacho_2024_c4_corr.shape}')\n",
    "print(f'villegas_camacho_2024_c8:  {villegas_camacho_2024_c8_corr.shape}')\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52200235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing 'study' column from 1st derivative datasets...\n",
      "\n",
      "✓ Cleanup complete for 1st derivatives\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRemoving 'study' column from 1st derivative datasets...\\n\")\n",
    "\n",
    "# Remove 'study' column from all 1st derivative datasets\n",
    "jung_2018_deriv1.drop(columns=['study'], inplace=True)\n",
    "kedzierski_2019_deriv1.drop(columns=['study'], inplace=True)\n",
    "kedzierski_2019_u_deriv1.drop(columns=['study'], inplace=True)\n",
    "frond_2021_deriv1.drop(columns=['study'], inplace=True)\n",
    "villegas_camacho_2024_c4_deriv1.drop(columns=['study'], inplace=True)\n",
    "villegas_camacho_2024_c8_deriv1.drop(columns=['study'], inplace=True)\n",
    "\n",
    "print(\"✓ Cleanup complete for 1st derivatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cd432f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "1ST DERIVATIVE DATA SHAPES\n",
      "================================================================================\n",
      "jung_2018:                 (800, 2325)\n",
      "kedzierski_2019:           (970, 1766)\n",
      "kedzierski_2019_u:         (4064, 1767)\n",
      "frond_2021:                (380, 1208)\n",
      "villegas_camacho_2024_c4:  (3000, 2412)\n",
      "villegas_camacho_2024_c8:  (3000, 1208)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1ST DERIVATIVE DATA SHAPES\")\n",
    "print(\"=\"*80)\n",
    "print(f'jung_2018:                 {jung_2018_deriv1.shape}')\n",
    "print(f'kedzierski_2019:           {kedzierski_2019_deriv1.shape}')\n",
    "print(f'kedzierski_2019_u:         {kedzierski_2019_u_deriv1.shape}')\n",
    "print(f'frond_2021:                {frond_2021_deriv1.shape}')\n",
    "print(f'villegas_camacho_2024_c4:  {villegas_camacho_2024_c4_deriv1.shape}')\n",
    "print(f'villegas_camacho_2024_c8:  {villegas_camacho_2024_c8_deriv1.shape}')\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdf7714a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing 'study' column from 2nd derivative datasets...\n",
      "\n",
      "✓ Cleanup complete for 2nd derivatives\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRemoving 'study' column from 2nd derivative datasets...\\n\")\n",
    "\n",
    "# Remove 'study' column from all 2nd derivative datasets\n",
    "jung_2018_deriv2.drop(columns=['study'], inplace=True)\n",
    "kedzierski_2019_deriv2.drop(columns=['study'], inplace=True)\n",
    "kedzierski_2019_u_deriv2.drop(columns=['study'], inplace=True)\n",
    "frond_2021_deriv2.drop(columns=['study'], inplace=True)\n",
    "villegas_camacho_2024_c4_deriv2.drop(columns=['study'], inplace=True)\n",
    "villegas_camacho_2024_c8_deriv2.drop(columns=['study'], inplace=True)\n",
    "\n",
    "print(\"✓ Cleanup complete for 2nd derivatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62cad717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "2ND DERIVATIVE DATA SHAPES\n",
      "================================================================================\n",
      "jung_2018:                 (800, 2325)\n",
      "kedzierski_2019:           (970, 1766)\n",
      "kedzierski_2019_u:         (4064, 1767)\n",
      "frond_2021:                (380, 1208)\n",
      "villegas_camacho_2024_c4:  (3000, 2412)\n",
      "villegas_camacho_2024_c8:  (3000, 1208)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2ND DERIVATIVE DATA SHAPES\")\n",
    "print(\"=\"*80)\n",
    "print(f'jung_2018:                 {jung_2018_deriv2.shape}')\n",
    "print(f'kedzierski_2019:           {kedzierski_2019_deriv2.shape}')\n",
    "print(f'kedzierski_2019_u:         {kedzierski_2019_u_deriv2.shape}')\n",
    "print(f'frond_2021:                {frond_2021_deriv2.shape}')\n",
    "print(f'villegas_camacho_2024_c4:  {villegas_camacho_2024_c4_deriv2.shape}')\n",
    "print(f'villegas_camacho_2024_c8:  {villegas_camacho_2024_c8_deriv2.shape}')\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba4bb46",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Combine All Datasets\n",
    "\n",
    "Now we'll combine all individual datasets into unified files. The `combine_datasets()` function:\n",
    "- Interpolates all spectra to a common wavenumber grid\n",
    "- Ensures consistent resolution across all studies\n",
    "- Adds study name column for tracking dataset origin\n",
    "- Handles different wavenumber ranges automatically\n",
    "\n",
    "### Parameters Explained:\n",
    "\n",
    "- **wn_min, wn_max**: Define the common wavenumber range (680-3000 cm⁻¹)\n",
    "- **resolution**: Common resolution for all spectra (2.0 cm⁻¹)\n",
    "- **descending**: Wavenumber order (True = high to low, typical for FTIR)\n",
    "- **method**: Interpolation method (\"pchip\" = Piecewise Cubic Hermite Interpolating Polynomial, recommended for smooth data)\n",
    "- **add_study_column**: Metadata columns to preserve\n",
    "- **study_names**: Names for each dataset (for tracking)\n",
    "- **n_jobs**: Number of parallel jobs for faster processing\n",
    "\n",
    "### Combine Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32fcf555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Intersection approach is discarding 31.7% of total spectral range. Union range: 600-3998 cm⁻¹ (3398 cm⁻¹), Target range: 680-3000 cm⁻¹ (2320 cm⁻¹). Consider using grid_mode='union' to preserve all spectral regions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMBINING NORMALIZED DATASETS\n",
      "================================================================================\n",
      "This will interpolate all datasets to a common wavenumber grid...\n",
      "Parameters: wn_range=(680, 3000), resolution=2.0 cm⁻¹, method='pchip'\n",
      "\n",
      "\n",
      "======================================================================\n",
      "DATASET COVERAGE ANALYSIS\n",
      "======================================================================\n",
      "Target grid: 680.0 - 3000.0 cm⁻¹ (2320.0 cm⁻¹ range)\n",
      "Grid mode: intersection\n",
      "----------------------------------------------------------------------\n",
      "  jung_2018: 800 samples, range 680.0-3000.0 cm⁻¹, coverage: ✓ FULL\n",
      "  kedzierski_2019: 970 samples, range 599.8-3996.0 cm⁻¹, coverage: ✓ FULL\n",
      "  kedzierski_2019_u: 4064 samples, range 599.8-3997.9 cm⁻¹, coverage: ✓ FULL\n",
      "  frond_2021: 380 samples, range 680.8-3000.8 cm⁻¹, coverage: ✓ FULL\n",
      "  villegas_camacho_2024_c4: 3000 samples, range 679.8-3000.7 cm⁻¹, coverage: ✓ FULL\n",
      "  villegas_camacho_2024_c8: 3000 samples, range 680.7-3000.7 cm⁻¹, coverage: ✓ FULL\n",
      "----------------------------------------------------------------------\n",
      "Total: 12214 samples, 12214 with full coverage (100.0%)\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling (pchip): 100%|██████████| 800/800 [00:01<00:00, 481.16it/s]\n",
      "WARNING - Spectral columns are not in ascending wavenumber order. Output DataFrame will have columns sorted by ascending wavenumber for standardization.\n",
      "Resampling (pchip): 100%|██████████| 970/970 [00:00<00:00, 21457.30it/s]\n",
      "WARNING - Spectral columns are not in ascending wavenumber order. Output DataFrame will have columns sorted by ascending wavenumber for standardization.\n",
      "Resampling (pchip): 100%|██████████| 4064/4064 [00:00<00:00, 27812.74it/s]\n",
      "Resampling (pchip): 100%|██████████| 380/380 [00:00<00:00, 14928.45it/s]\n",
      "Resampling (pchip): 100%|██████████| 3000/3000 [00:00<00:00, 18601.42it/s]\n",
      "Resampling (pchip): 100%|██████████| 3000/3000 [00:00<00:00, 33625.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving combined normalized data...\n",
      "✓ Saved: combined_norm_data.csv.xz (shape: (12214, 1166))\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMBINING NORMALIZED DATASETS\")\n",
    "print(\"=\"*80)\n",
    "print(\"This will interpolate all datasets to a common wavenumber grid...\")\n",
    "print(\"Parameters: wn_range=(680, 3000), resolution=2.0 cm⁻¹, method='pchip'\\n\")\n",
    "\n",
    "from xpectrass import combine_datasets\n",
    "\n",
    "# Combine all normalized datasets into a single file\n",
    "combined_norm_data, _ = combine_datasets(\n",
    "    datasets=[\n",
    "        jung_2018_corr, \n",
    "        kedzierski_2019_corr, \n",
    "        kedzierski_2019_u_corr,\n",
    "        frond_2021_corr, \n",
    "        villegas_camacho_2024_c4_corr,\n",
    "        villegas_camacho_2024_c8_corr\n",
    "    ],\n",
    "    wn_min=680,\n",
    "    wn_max=3000,\n",
    "    resolution=2.0,\n",
    "    descending=True,\n",
    "    method=\"pchip\",\n",
    "    label_column=\"type\",\n",
    "    exclude_columns=None,\n",
    "    add_study_column=['sample_id', 'environmental', 'resolution'],\n",
    "    study_names=[\n",
    "        'jung_2018', \n",
    "        'kedzierski_2019', \n",
    "        'kedzierski_2019_u',\n",
    "        'frond_2021', \n",
    "        'villegas_camacho_2024_c4',\n",
    "        'villegas_camacho_2024_c8'\n",
    "    ],\n",
    "    show_progress=True,\n",
    "    n_jobs=12,\n",
    "    data_mode=\"normalized\"\n",
    ")\n",
    "\n",
    "# Save to compressed CSV\n",
    "print(\"\\nSaving combined normalized data...\")\n",
    "combined_norm_data.to_csv('processed_data/combined_norm_data.csv.xz', compression='xz', index=None)\n",
    "print(f\"✓ Saved: combined_norm_data.csv.xz (shape: {combined_norm_data.shape})\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fqb9xev2as",
   "metadata": {},
   "source": [
    "### Combine 1st Derivative Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "492664fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Intersection approach is discarding 31.7% of total spectral range. Union range: 600-3998 cm⁻¹ (3398 cm⁻¹), Target range: 680-3000 cm⁻¹ (2320 cm⁻¹). Consider using grid_mode='union' to preserve all spectral regions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMBINING 1ST DERIVATIVE DATASETS\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "DATASET COVERAGE ANALYSIS\n",
      "======================================================================\n",
      "Target grid: 680.0 - 3000.0 cm⁻¹ (2320.0 cm⁻¹ range)\n",
      "Grid mode: intersection\n",
      "----------------------------------------------------------------------\n",
      "  jung_2018: 800 samples, range 680.0-3000.0 cm⁻¹, coverage: ✓ FULL\n",
      "  kedzierski_2019: 970 samples, range 599.8-3996.0 cm⁻¹, coverage: ✓ FULL\n",
      "  kedzierski_2019_u: 4064 samples, range 599.8-3997.9 cm⁻¹, coverage: ✓ FULL\n",
      "  frond_2021: 380 samples, range 680.8-3000.8 cm⁻¹, coverage: ✓ FULL\n",
      "  villegas_camacho_2024_c4: 3000 samples, range 679.8-3000.7 cm⁻¹, coverage: ✓ FULL\n",
      "  villegas_camacho_2024_c8: 3000 samples, range 680.7-3000.7 cm⁻¹, coverage: ✓ FULL\n",
      "----------------------------------------------------------------------\n",
      "Total: 12214 samples, 12214 with full coverage (100.0%)\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling (pchip): 100%|██████████| 800/800 [00:00<00:00, 17547.37it/s]\n",
      "Resampling (pchip): 100%|██████████| 970/970 [00:00<00:00, 23787.38it/s]\n",
      "Resampling (pchip): 100%|██████████| 4064/4064 [00:00<00:00, 29885.67it/s]\n",
      "Resampling (pchip): 100%|██████████| 380/380 [00:00<00:00, 14697.31it/s]\n",
      "Resampling (pchip): 100%|██████████| 3000/3000 [00:00<00:00, 20276.28it/s]\n",
      "Resampling (pchip): 100%|██████████| 3000/3000 [00:00<00:00, 40918.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving combined 1st derivative data...\n",
      "✓ Saved: combined_deriv1_data.csv.xz (shape: (12214, 1166))\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMBINING 1ST DERIVATIVE DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Combine all 1st derivative datasets\n",
    "combined_deriv1_data, _ = combine_datasets(\n",
    "    datasets=[\n",
    "        jung_2018_deriv1, \n",
    "        kedzierski_2019_deriv1, \n",
    "        kedzierski_2019_u_deriv1,\n",
    "        frond_2021_deriv1, \n",
    "        villegas_camacho_2024_c4_deriv1,\n",
    "        villegas_camacho_2024_c8_deriv1\n",
    "    ],\n",
    "    wn_min=680,\n",
    "    wn_max=3000,\n",
    "    resolution=2.0,\n",
    "    descending=True,\n",
    "    method=\"pchip\",\n",
    "    label_column=\"type\",\n",
    "    exclude_columns=None,\n",
    "    add_study_column=['sample_id', 'environmental', 'resolution'],\n",
    "    study_names=[\n",
    "        'jung_2018', \n",
    "        'kedzierski_2019', \n",
    "        'kedzierski_2019_u',\n",
    "        'frond_2021', \n",
    "        'villegas_camacho_2024_c4',\n",
    "        'villegas_camacho_2024_c8'\n",
    "    ],\n",
    "    show_progress=True,\n",
    "    n_jobs=12,\n",
    "    data_mode=\"normalized\"\n",
    ")\n",
    "\n",
    "# Save to compressed CSV\n",
    "print(\"\\nSaving combined 1st derivative data...\")\n",
    "combined_deriv1_data.to_csv('processed_data/combined_deriv1_data.csv.xz', compression='xz', index=None)\n",
    "print(f\"✓ Saved: combined_deriv1_data.csv.xz (shape: {combined_deriv1_data.shape})\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hpkxgdeffxh",
   "metadata": {},
   "source": [
    "### Combine 2nd Derivative Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83dd6d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Intersection approach is discarding 31.7% of total spectral range. Union range: 600-3998 cm⁻¹ (3398 cm⁻¹), Target range: 680-3000 cm⁻¹ (2320 cm⁻¹). Consider using grid_mode='union' to preserve all spectral regions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMBINING 2ND DERIVATIVE DATASETS\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "DATASET COVERAGE ANALYSIS\n",
      "======================================================================\n",
      "Target grid: 680.0 - 3000.0 cm⁻¹ (2320.0 cm⁻¹ range)\n",
      "Grid mode: intersection\n",
      "----------------------------------------------------------------------\n",
      "  jung_2018: 800 samples, range 680.0-3000.0 cm⁻¹, coverage: ✓ FULL\n",
      "  kedzierski_2019: 970 samples, range 599.8-3996.0 cm⁻¹, coverage: ✓ FULL\n",
      "  kedzierski_2019_u: 4064 samples, range 599.8-3997.9 cm⁻¹, coverage: ✓ FULL\n",
      "  frond_2021: 380 samples, range 680.8-3000.8 cm⁻¹, coverage: ✓ FULL\n",
      "  villegas_camacho_2024_c4: 3000 samples, range 679.8-3000.7 cm⁻¹, coverage: ✓ FULL\n",
      "  villegas_camacho_2024_c8: 3000 samples, range 680.7-3000.7 cm⁻¹, coverage: ✓ FULL\n",
      "----------------------------------------------------------------------\n",
      "Total: 12214 samples, 12214 with full coverage (100.0%)\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling (pchip): 100%|██████████| 800/800 [00:00<00:00, 17387.52it/s]\n",
      "Resampling (pchip): 100%|██████████| 970/970 [00:00<00:00, 19247.94it/s]\n",
      "Resampling (pchip): 100%|██████████| 4064/4064 [00:00<00:00, 21714.40it/s]\n",
      "Resampling (pchip): 100%|██████████| 380/380 [00:00<00:00, 9280.30it/s]\n",
      "Resampling (pchip): 100%|██████████| 3000/3000 [00:00<00:00, 15804.52it/s]\n",
      "Resampling (pchip): 100%|██████████| 3000/3000 [00:00<00:00, 39192.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving combined 2nd derivative data...\n",
      "✓ Saved: combined_deriv2_data.csv.xz (shape: (12214, 1166))\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMBINING 2ND DERIVATIVE DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Combine all 2nd derivative datasets\n",
    "combined_deriv2_data, _ = combine_datasets(\n",
    "    datasets=[\n",
    "        jung_2018_deriv2, \n",
    "        kedzierski_2019_deriv2, \n",
    "        kedzierski_2019_u_deriv2,\n",
    "        frond_2021_deriv2, \n",
    "        villegas_camacho_2024_c4_deriv2,\n",
    "        villegas_camacho_2024_c8_deriv2\n",
    "    ],\n",
    "    wn_min=680,\n",
    "    wn_max=3000,\n",
    "    resolution=2.0,\n",
    "    descending=True,\n",
    "    method=\"pchip\",\n",
    "    label_column=\"type\",\n",
    "    exclude_columns=None,\n",
    "    add_study_column=['sample_id', 'environmental', 'resolution'],\n",
    "    study_names=[\n",
    "        'jung_2018', \n",
    "        'kedzierski_2019', \n",
    "        'kedzierski_2019_u',\n",
    "        'frond_2021', \n",
    "        'villegas_camacho_2024_c4',\n",
    "        'villegas_camacho_2024_c8'\n",
    "    ],\n",
    "    show_progress=True,\n",
    "    n_jobs=12,\n",
    "    data_mode=\"normalized\"\n",
    ")\n",
    "\n",
    "# Save to compressed CSV\n",
    "print(\"\\nSaving combined 2nd derivative data...\")\n",
    "combined_deriv2_data.to_csv('processed_data/combined_deriv2_data.csv.xz', compression='xz', index=None)\n",
    "print(f\"✓ Saved: combined_deriv2_data.csv.xz (shape: {combined_deriv2_data.shape})\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p9jhke77vup",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Compute Derivatives of Combined Normalized Data\n",
    "\n",
    "Finally, we'll compute 1st and 2nd derivatives of the combined normalized dataset. This provides an alternative to combining the derivatives of individual datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0174a6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPUTING DERIVATIVES OF COMBINED NORMALIZED DATA\n",
      "================================================================================\n",
      "\n",
      "→ Computing 1st derivative of combined data...\n",
      "Computing 1st derivative for 12214 samples...\n",
      "→ Computing 2nd derivative of combined data...\n",
      "Computing 2nd derivative for 12214 samples...\n",
      "\n",
      "→ Saving combined normalized derivative data...\n",
      "✓ Saved: combined_norm_deriv1_data.csv.xz (shape: (12214, 1166))\n",
      "✓ Saved: combined_norm_deriv2_data.csv.xz (shape: (12214, 1166))\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPUTING DERIVATIVES OF COMBINED NORMALIZED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize FTIRdataprocessing class for combined data\n",
    "fdp = FTIRdataprocessing(\n",
    "    df=combined_norm_data,\n",
    "    label_column=LABEL_COLUMN,\n",
    "    exclude_regions=EXCLUDE_REGIONS,\n",
    "    interpolate_regions=INTERPOLATE_REGIONS,\n",
    "    flat_windows=FLAT_WINDOWS\n",
    ")\n",
    "\n",
    "# Compute 1st derivative of combined normalized data\n",
    "print(\"\\n→ Computing 1st derivative of combined data...\")\n",
    "combined_norm_deriv1_data = fdp.derivatives(\n",
    "    data=combined_norm_data,\n",
    "    order=1,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "# Compute 2nd derivative of combined normalized data\n",
    "print(\"→ Computing 2nd derivative of combined data...\")\n",
    "combined_norm_deriv2_data = fdp.derivatives(\n",
    "    data=combined_norm_data,\n",
    "    order=2,\n",
    "    window_length=15,\n",
    "    polyorder=3,\n",
    "    delta=1.0,\n",
    "    plot=False,\n",
    "    save_plot=False,\n",
    "    save_path=None,\n",
    ")\n",
    "\n",
    "# Save both derivative datasets\n",
    "print(\"\\n→ Saving combined normalized derivative data...\")\n",
    "combined_norm_deriv1_data.to_csv('processed_data/combined_norm_deriv1_data.csv.xz', compression='xz', index=None)\n",
    "combined_norm_deriv2_data.to_csv('processed_data/combined_norm_deriv2_data.csv.xz', compression='xz', index=None)\n",
    "\n",
    "print(f\"✓ Saved: combined_norm_deriv1_data.csv.xz (shape: {combined_norm_deriv1_data.shape})\")\n",
    "print(f\"✓ Saved: combined_norm_deriv2_data.csv.xz (shape: {combined_norm_deriv2_data.shape})\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ovvxipje8zo",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Next Steps\n",
    "\n",
    "### Files Created\n",
    "\n",
    "This notebook has created the following preprocessed data files:\n",
    "\n",
    "**Combined Datasets:**\n",
    "1. `combined_norm_data.csv.xz` - All datasets combined, normalized\n",
    "2. `combined_deriv1_data.csv.xz` - All datasets combined, 1st derivative  \n",
    "3. `combined_deriv2_data.csv.xz` - All datasets combined, 2nd derivative\n",
    "4. `combined_norm_deriv1_data.csv.xz` - 1st derivative of combined normalized data\n",
    "5. `combined_norm_deriv2_data.csv.xz` - 2nd derivative of combined normalized data\n",
    "\n",
    "All files are saved in compressed CSV format (.csv.xz) for efficient storage and fast loading.\n",
    "\n",
    "### File Sizes\n",
    "\n",
    "The compressed files are typically 10-20x smaller than uncompressed CSV files, making them ideal for:\n",
    "- Version control (if needed)\n",
    "- File transfer\n",
    "- Long-term storage\n",
    "- Fast loading with pandas/polars\n",
    "\n",
    "### Loading the Data\n",
    "\n",
    "To load these files in a future session:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load combined normalized data\n",
    "df = pd.read_csv('combined_norm_data.csv.xz', compression='xz')\n",
    "\n",
    "# Load combined 1st derivative data\n",
    "df_deriv1 = pd.read_csv('combined_deriv1_data.csv.xz', compression='xz')\n",
    "```\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "Your preprocessed data is now ready for:\n",
    "\n",
    "1. **Exploratory Data Analysis** (Notebook 6)\n",
    "   - Mean spectra visualization\n",
    "   - PCA, t-SNE, UMAP dimensionality reduction\n",
    "   - Statistical analysis (ANOVA, correlation)\n",
    "   - Clustering analysis\n",
    "\n",
    "2. **Machine Learning Classification** (Notebook 6)\n",
    "   - Train multiple classification models\n",
    "   - Hyperparameter tuning\n",
    "   - Model comparison\n",
    "   - SHAP explainability analysis\n",
    "\n",
    "3. **Custom Analysis**\n",
    "   - Export to other software\n",
    "   - Build custom models\n",
    "   - Publication-ready figures\n",
    "\n",
    "### Tips for Using the Combined Data\n",
    "\n",
    "- **combined_norm_data.csv.xz**: Use this for most analyses, as it's the fully preprocessed, normalized data\n",
    "- **combined_deriv1_data.csv.xz**: Use when you need enhanced spectral resolution (better peak separation)\n",
    "- **combined_deriv2_data.csv.xz**: Use for identifying overlapping peaks and subtle features\n",
    "- **Study column**: Each row contains a 'study' column indicating which dataset it came from\n",
    "\n",
    "### Data Characteristics\n",
    "\n",
    "- **Wavenumber range**: 680-3000 cm⁻¹ (consistent across all studies)\n",
    "- **Resolution**: 2.0 cm⁻¹ (all spectra interpolated to this resolution)\n",
    "- **Number of features**: 1161 wavenumber points\n",
    "- **Preprocessing applied**: Denoising → Baseline correction → Atmospheric correction → Normalization\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "You've successfully preprocessed and combined all 6 bundled FTIR datasets! The data is now optimally prepared for analysis. Proceed to Notebook 6 for exploratory data analysis and machine learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ToF-SIMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
